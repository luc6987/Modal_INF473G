{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from ipysigma import Sigma\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "/var/folders/0x/wfkkw0fs251d8m1m3p0ks01r0000gn/T/ipykernel_91436/2492789890.py:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWe will do the following steps:\\n    1. extract all the authors as nodes, and the collaboration as edges with the weight of the number of collaborations.\\n    2. extract the title as the name of the paper, the number of arxiv and attribute them to the nodes.\\n    3. find communities in the graph.\\n    5. use citation data to find the most important communities.\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "explanation of meta data:\n",
    "------------------------------------------------------------------------------\n",
    "\\\\\n",
    "Paper: hep-th/9201018\n",
    "From: OGURAWA@VTCC1.CC.VT.EDU\n",
    "Date: Thu, 9 Jan 1992 18:18:54 -0500 (EST)   (20kb)\n",
    "Date (revised): Mon, 13 Jan 1992 15:35:36 -0500 (EST)\n",
    "\n",
    "Title: Discrete and Continuum Virasoro Constraints in Two-Cut Hermitian Matrix\n",
    "  Models\n",
    "Authors: Waichi Ogura\n",
    "Comments: 25 pages\n",
    "Journal-ref: Prog.Theor.Phys. 89 (1993) 1311-1330\n",
    "\\\\\n",
    "  Continuum Virasoro constraints in the two-cut hermitian matrix models are\n",
    "derived from the discrete Ward identities by means of the mapping from the\n",
    "$GL(\\infty )$ Toda hierarchy to the nonlinear Schr\\\"odinger (NLS) hierarchy.\n",
    "The invariance of the string equation under the NLS flows is worked out. Also\n",
    "the quantization of the integration constant $\\alpha$ reported by Hollowood et\n",
    "al. is explained by the analyticity of the continuum limit.\n",
    "\\\\\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "We will do the following steps:\n",
    "    1. extract all the authors as nodes, and the collaboration as edges with the weight of the number of collaborations.\n",
    "    2. extract the title as the name of the paper, the number of arxiv and attribute them to the nodes.\n",
    "    3. find communities in the graph.\n",
    "    5. use citation data to find the most important communities.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "example of assets/Cit-HepTh.txt:\n",
    "# Directed graph (each unordered pair of nodes is saved once): assets/Cit-HepTh.txt \n",
    "# Paper citation network of Arxiv High Energy Physics Theory category\n",
    "# Nodes: 27770 Edges: 352807\n",
    "# FromNodeId\tToNodeId\n",
    "0001001\t9304045\n",
    "0001001\t9308122\n",
    "0001001\t9309097\n",
    "0001001\t9311042\n",
    "0001001\t9401139\n",
    "\n",
    "for each paper, we will add a new attribute of list that shows all the papers that this paper cite, with its arxiv number.\n",
    "We will add it iff both papers of a citation are in the paper. And save it to arxiv_papers.json.\n",
    "\n",
    "example of temp/papers_standardized.json\n",
    "\n",
    "  {\n",
    "    \"paper_id\": \"hep-th/9211063\",\n",
    "    \"from\": \"Malcolm Perry <M.J.Perry@damtp.cambridge.ac.uk>\",\n",
    "    \"submitted\": \"Sat, 14 Nov 92 17:58:35 GMT (27kb)\",\n",
    "    \"title\": \"Topological Conformal Gravity in Four Dimensions\",\n",
    "    \"authors\": [\n",
    "      \"Malcolm J. Perry\",\n",
    "      \"Edward Teo\"\n",
    "    ],\n",
    "    \"comments\": \"35 pages, harvmac, DAMTP R92/42\",\n",
    "    \"report_no\": null,\n",
    "    \"journal_ref\": \"Nucl.Phys. B401 (1993) 206-238\",\n",
    "    \"subject_class\": null,\n",
    "    \"proxy\": null,\n",
    "    \"abstract\": \"In this paper, we present a new formulation of topological conformal gravity in four dimensions. Such a theory was first considered by Witten as a possible gravitational counterpart of topological Yang-Mills theory, but several problems left it incomplete. The key in our approach is to realise a theory which describes deformations of conformally self-dual gravitational instantons. We first identify the appropriate elliptic complex which does precisely this. By applying the Atiyah-Singer index theorem, we calculate the number of independent deformations of a given gravitational instanton which preserve its self-duality. We then quantise topological conformal gravity by BRST gauge-fixing, and discover how the quantum theory is naturally described by the above complex. Indeed, it is a process which closely parallels that of the Yang-Mills theory, and we show how the partition function generates an uncanny gravitational analogue of the first Donaldson invariant.\",\n",
    "    \"year\": 1992\n",
    "  },\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#load data from temp/papers_standardized.json\n",
    "with open(\"temp/papers_standardized.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers = {paper[\"paper_id\"]: paper for paper in json.load(f)}\n",
    "\n",
    "\n",
    "# Load the citation data\n",
    "citations = {}\n",
    "with open(\"assets/Cit-HepTh.txt\", \"r\") as f:\n",
    "    # Skip the lines with comments\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line.startswith(\"#\"):\n",
    "            break\n",
    "    for line in f:\n",
    "        source, target = map(int, line.strip().split())\n",
    "        source = str(source)\n",
    "        target = str(target)\n",
    "        if source in papers and target in papers:\n",
    "            if source not in citations:\n",
    "                citations[source] = []\n",
    "            citations[source].append(target)\n",
    "\n",
    "# Add the citation of the papers and the paper cited by the papers\n",
    "for paper_id, data in papers.items():\n",
    "    if paper_id in citations:\n",
    "        data[\"citations\"] = citations[paper_id]\n",
    "    else:\n",
    "        data[\"citations\"] = []\n",
    "\n",
    "\n",
    "# Save the updated data\n",
    "with open(\"temp/arxiv_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 8187\n",
      "Number of edges: 19205\n"
     ]
    }
   ],
   "source": [
    "# create a graph with authors as nodes and collaborations as edges\n",
    "\n",
    "Ghep = nx.Graph()\n",
    "for paper in papers.values():\n",
    "    for author in paper[\"authors\"]:\n",
    "        if author not in Ghep:\n",
    "            Ghep.add_node(author, papers=[])\n",
    "            # Add the paper with its arxiv numbres to the author's list \n",
    "        Ghep.nodes[author][\"papers\"].append(paper[\"title\"])\n",
    "\n",
    "    for author1 in paper[\"authors\"]:\n",
    "        for author2 in paper[\"authors\"]:\n",
    "            if author1 != author2:\n",
    "                if not Ghep.has_edge(author1, author2):\n",
    "                    Ghep.add_edge(author1, author2, weight=0)\n",
    "                Ghep[author1][author2][\"weight\"] += 1\n",
    "\n",
    "print(f\"Number of nodes: {Ghep.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {Ghep.number_of_edges()}\")\n",
    "\n",
    "#print all the authors with the number of collaborations in temp/authors.csv in alphabetical order\n",
    "with open(\"temp/authors_list.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Author,Number of collaborations\\n\")\n",
    "    for author in sorted(Ghep.nodes):\n",
    "        f.write(f\"{author},{Ghep.degree(author)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542\n",
      "1161\n",
      "1994\n"
     ]
    }
   ],
   "source": [
    "# find communities in the graph\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "\n",
    "# Louvain community detection\n",
    "lc_Ghep = louvain_communities(Ghep,resolution=40.0, seed=123)\n",
    "\n",
    "#print the community number\n",
    "print(len(lc_Ghep))\n",
    "# Clique percolation method\n",
    "from networkx.algorithms.community import k_clique_communities\n",
    "cp_Ghep= k_clique_communities(Ghep,3)\n",
    "#print the community number\n",
    "print(len(list(cp_Ghep)))\n",
    "\n",
    "\n",
    "\n",
    "# label propagation algorithm\n",
    "from networkx.algorithms.community.label_propagation import label_propagation_communities\n",
    "lp_Ghep = list(label_propagation_communities(Ghep))\n",
    "#print the community number\n",
    "print(len(lp_Ghep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important communities:\n",
      "Community 1: 23 authors, 3146.0 citations\n",
      "  Joanna L. Karczmarek\n",
      "  N. Sochen J. Sonnenschein\n",
      "  Yoav Lavi\n",
      "  Shlomo S. Razamat\n",
      "  A. Loewy\n",
      "  Eugene A. Mirabelli\n",
      "  Morten Krogh\n",
      "  Nissan Itzhaki\n",
      "  Ori J. Ganor\n",
      "  Adi Armoni\n",
      "  Aaron Bergman\n",
      "  Y. Kinar\n",
      "  Andreas Brandhuber\n",
      "  Shimon Yankielowicz\n",
      "  S. Yankielowizc\n",
      "  Yitzhak Frishman\n",
      "  Mordechai Spiegelglas\n",
      "  Ehud Schreiber\n",
      "  C. Sonnenschein\n",
      "  Ofer Aharony\n",
      "  Vadim S. Kaplunovsky\n",
      "  Y. Artstein\n",
      "  Michael E. Peskin\n",
      "Community 2: 14 authors, 2179.0 citations\n",
      "  David C. Lewellen\n",
      "  Gerald B. Cleaver\n",
      "  R. L. Davis\n",
      "  Mirjam Cvetic\n",
      "  Mirjam Cvetiv C\n",
      "  Philip J. Rosenthal\n",
      "  Harald H. Soleng\n",
      "  Paul Langacker\n",
      "  Jose R. Espinosa\n",
      "  Donam Youm\n",
      "  Kwanleung Chan\n",
      "  Stephen Griffies\n",
      "  Mirjam Cvetivc\n",
      "  Lisa Everett\n",
      "Community 3: 15 authors, 2129.0 citations\n",
      "  Curtis G. Callan\n",
      "  A. M. Polyakov\n",
      "  Ali Yegulalp\n",
      "  Arkadas Ozakin\n",
      "  Akikazu Hashimoto\n",
      "  Krev Simir Demeterfi\n",
      "  Michael Krasnitz\n",
      "  Christof Schmidhuber\n",
      "  Peter Ouyang\n",
      "  Shivaji L. Sondhi\n",
      "  Christopher P. Herzog\n",
      "  Steven S. Gubser\n",
      "  G.V. Bhanot\n",
      "  Igor R. Klebanov\n",
      "  Vyacheslav S. Rychkov\n",
      "Community 4: 11 authors, 1927.0 citations\n",
      "  R.R. Metsaev\n",
      "  Hongya Liu\n",
      "  Angelos Fotopoulos\n",
      "  Jeremy Michelson\n",
      "  Iouri Chepelev\n",
      "  Junseong Heo\n",
      "  Lawrence M. Krauss\n",
      "  Jorge G. Russo\n",
      "  Daniele Amati\n",
      "  Arkady A. Tseytlin\n",
      "  Guowen Peng\n",
      "Community 5: 16 authors, 1895.0 citations\n",
      "  Davide Gaiotto\n",
      "  Amer Iqbal\n",
      "  Tamas Hauer\n",
      "  K. Ranganathan\n",
      "  Barton Zwiebach\n",
      "  Jaydeep Majumder\n",
      "  Oliver Dewolfe\n",
      "  O. Bertolami\n",
      "  Hidenori Sonoda\n",
      "  M. C. Bento\n",
      "  Leonardo Rastelli\n",
      "  R. Saroja\n",
      "  Wangchang Su\n",
      "  Anjan Ananda Sen\n",
      "  Sabbir Rahman\n",
      "  Alexander Belopolsky\n",
      "Community 6: 13 authors, 1856.0 citations\n",
      "  A. Resturccia\n",
      "  T. Magri\n",
      "  Anna Ceresole\n",
      "  A.C. Cadavid\n",
      "  Laura Andrianopoli\n",
      "  Floriana Gargiulo\n",
      "  S. Ferrara Amd M. A. Lledo\n",
      "  Riccardo Dauria\n",
      "  V.S.V. Varadarajan\n",
      "  M. Villasante\n",
      "  T. Regge\n",
      "  Sergio Ferrara\n",
      "  Silvia Vaula\n",
      "Community 7: 20 authors, 1617.0 citations\n",
      "  Piljin Yi\n",
      "  Kyoungtae Kimm\n",
      "  Jin Hur\n",
      "  Hsienchung Kao\n",
      "  Branko Urosevic\n",
      "  Bugra Borasoy\n",
      "  Yuval Neeman\n",
      "  Seoktae Koh\n",
      "  Nathan Salwen\n",
      "  Yun Soo Myung\n",
      "  W.F. Chen. H.C. Lee\n",
      "  Georgios Metikas\n",
      "  Yoji Michishita\n",
      "  Paul F. Mende\n",
      "  Minyoung Choi\n",
      "  Erick A. Roura\n",
      "  Tzedan Chung\n",
      "  Pablo J. Marrero\n",
      "  W. S. Lyi\n",
      "  Gungwon Kang\n",
      "Community 8: 17 authors, 1487.0 citations\n",
      "  J. C. Breckenridge\n",
      "  Clifford V. Johnson\n",
      "  Adel M. Awad\n",
      "  G. Michaud\n",
      "  Hoseong La\n",
      "  Kenneth J. Lovis\n",
      "  O Yvind Tafjord\n",
      "  J.D. Cohn\n",
      "  Ramzi R. Khuri\n",
      "  Robert C. Myers\n",
      "  J.R. Anglin\n",
      "  Vipul Periwal\n",
      "  Luc Marleau\n",
      "  Laur Jarv\n",
      "  Frederic Leblond\n",
      "  David J. Winters\n",
      "  David C. Page\n",
      "Community 9: 16 authors, 1456.0 citations\n",
      "  Kenji Mohri\n",
      "  Takeo Araki\n",
      "  Huanxiong Yang\n",
      "  Seiji Terashima\n",
      "  Byungkoo Lee\n",
      "  Kyungseok Cha\n",
      "  Tohru Eguchi\n",
      "  Toshiya Kawai\n",
      "  Kazuhiro Sakai\n",
      "  Yoko Onjo\n",
      "  Yasuhiko Yamada\n",
      "  Hiroaki Kanno\n",
      "  Katsushi Ito\n",
      "  Koichi Yoshioka\n",
      "  Jiro Hashiba\n",
      "  Ianwoo Kim\n",
      "Community 10: 12 authors, 1408.0 citations\n",
      "  Stefano Kovacs\n",
      "  Augusto Sagnotti\n",
      "  Massimo Bianchi\n",
      "  Emilian Dudas\n",
      "  Carlo Angelantonj\n",
      "  C. Timirgaziu\n",
      "  Giuseppe Dappollonio\n",
      "  Fabio Riccioni\n",
      "  Gianfranco Pradisi\n",
      "  Jihad Mourad\n",
      "  Yassen S. Stanev\n",
      "  Giancarlo Rossi\n"
     ]
    }
   ],
   "source": [
    "#calculate the net citations numbers between communities directly from the temp/arxiv_papers.json\n",
    "\n",
    "\"\"\"\n",
    "First few lines of the temp/arxiv_papers.json:\n",
    "{\n",
    "    \"9203077\": {\n",
    "        \"title\": \"Finite W-algebras\",\n",
    "        \"authors\": [\n",
    "            \"T.Tjin\"\n",
    "        ],\n",
    "        \"citations\": 13,\n",
    "        \"cited_by\": []\n",
    "    },\n",
    "    \"9203063\": {\n",
    "        \"title\": \"The Spectrum of Sl(2, R)/U(1) Black Hole Conformal Field Theory\",\n",
    "        \"authors\": [\n",
    "            \"Dileep P. Jatkar\"\n",
    "        ],\n",
    "        \"citations\": 0,\n",
    "        \"cited_by\": []\n",
    "    },\n",
    "    \"9212146\": {\n",
    "\"\"\"\n",
    "communities = list(lc_Ghep)  # Use the Louvain communities\n",
    "# Load the papers data\n",
    "with open(\"temp/arxiv_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "# Create a dictionary of authors to communities\n",
    "author_community = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for author in community:\n",
    "        author_community[author] = i\n",
    "\n",
    "# Calculate the net citations between communities\n",
    "net_citations = np.zeros((len(communities), len(communities)))\n",
    "for paper in papers.values():\n",
    "    if \"citations\" not in paper:\n",
    "        continue\n",
    "    # Ensure the source author exists in the author_community dictionary\n",
    "    if paper[\"authors\"]:\n",
    "        source_community = author_community.get(paper[\"authors\"][0], -1)\n",
    "        if source_community != -1:\n",
    "            for target in paper[\"citations\"]:\n",
    "                # Ensure the target paper exists and has authors\n",
    "                if target in papers and papers[target][\"authors\"]:\n",
    "                    target_community = author_community.get(papers[target][\"authors\"][0], -1)\n",
    "                    if target_community != -1:\n",
    "                        net_citations[source_community, target_community] += 1\n",
    "\n",
    "\n",
    "# Find the most important communities by net citations/\n",
    "community_citations = net_citations.sum(axis=1)\n",
    "most_important_communities = np.argsort(community_citations)[::-1]  \n",
    "\n",
    "print(\"Most important communities:\")\n",
    "for i in range(10):\n",
    "    community = communities[most_important_communities[i]]\n",
    "    print(f\"Community {i + 1}: {len(community)} authors, {community_citations[most_important_communities[i]]} citations\")\n",
    "    for author in community:\n",
    "        print(f\"  {author}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1542\n",
      "Number of edges: 13053\n"
     ]
    }
   ],
   "source": [
    "#create a graph of communities as summation of the information of the authors named after the most important author in the community.\n",
    "# we will create a graph of communities as summation of the information of the authors named after the most important author in the community. \n",
    "# The number of citations as the weight of the edges.\n",
    "G_communities = nx.Graph()\n",
    "for i, community in enumerate(communities):\n",
    "    most_important_author = max(community, key=lambda x: len(papers[x][\"papers\"]) if x in papers else 0)\n",
    "    G_communities.add_node(i, name=most_important_author, size=len(community))\n",
    "    #add the number of members in the community as the size of the node\n",
    "    #add the authors as attributes to the node\n",
    "    G_communities.nodes[i][\"authors\"] = community\n",
    "\n",
    "    #add the total citations in the community\n",
    "    G_communities.nodes[i][\"total_citations\"] = community_citations[i]\n",
    "\n",
    "# Create the edges between communities based on the net citations\n",
    "for i in range(len(communities)):\n",
    "    for j in range(i + 1, len(communities)):\n",
    "        # Add the number of citations as the weight of the edge with weight of the number of citations\n",
    "        if net_citations[i][j] > 0:\n",
    "            G_communities.add_edge(i, j, weight=net_citations[i][j])\n",
    "\n",
    "print(f\"Number of nodes: {G_communities.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G_communities.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe34917147264cfaa521dce695a6491a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sigma(nx.Graph with 1,542 nodes and 13,053 edges)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the graph of G_communities with ipysigma\n",
    "\n",
    "# Assign colors to each communities based on the numbers of members of communities from red to blue\n",
    "\n",
    "for node in G_communities.nodes:\n",
    "    r = max(0, min(255, 255 - 20 * len(communities[node])))\n",
    "    g = max(0, min(255, 20 * len(communities[node])))\n",
    "    G_communities.nodes[node][\"colors\"] = f\"rgb({r}, O,{g})\"\n",
    "\n",
    "# assgin the color of the edges based on the citations of the community\n",
    "for i, j in G_communities.edges:\n",
    "    G_communities.edges[i, j][\"color\"] = f\"rgb({255 - 20 * net_citations[i, j]}, {20 * net_citations[i, j]}, 0)\"\n",
    "    \n",
    "# Assign the size of the nodes based on citations\n",
    "for node in G_communities.nodes:\n",
    "    G_communities.nodes[node][\"size\"] = G_communities.nodes[node][\"total_citations\"] / 100\n",
    "\n",
    "# Visualize with ipysigma\n",
    "sigma = Sigma(\n",
    "    G_communities,\n",
    "    node_color=\"colors\",\n",
    "    edge_color=\"color\",\n",
    "    node_label=\"name\",\n",
    "    node_size=\"size\",\n",
    "    label_font=\"cursive\",\n",
    "    default_edge_type=\"curve\"\n",
    ")\n",
    "\n",
    "sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
