{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from ipysigma import Sigma\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "/var/folders/0x/wfkkw0fs251d8m1m3p0ks01r0000gn/T/ipykernel_47058/2492789890.py:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWe will do the following steps:\\n    1. extract all the authors as nodes, and the collaboration as edges with the weight of the number of collaborations.\\n    2. extract the title as the name of the paper, the number of arxiv and attribute them to the nodes.\\n    3. find communities in the graph.\\n    5. use citation data to find the most important communities.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "explanation of meta data:\n",
    "------------------------------------------------------------------------------\n",
    "\\\\\n",
    "Paper: hep-th/9201018\n",
    "From: OGURAWA@VTCC1.CC.VT.EDU\n",
    "Date: Thu, 9 Jan 1992 18:18:54 -0500 (EST)   (20kb)\n",
    "Date (revised): Mon, 13 Jan 1992 15:35:36 -0500 (EST)\n",
    "\n",
    "Title: Discrete and Continuum Virasoro Constraints in Two-Cut Hermitian Matrix\n",
    "  Models\n",
    "Authors: Waichi Ogura\n",
    "Comments: 25 pages\n",
    "Journal-ref: Prog.Theor.Phys. 89 (1993) 1311-1330\n",
    "\\\\\n",
    "  Continuum Virasoro constraints in the two-cut hermitian matrix models are\n",
    "derived from the discrete Ward identities by means of the mapping from the\n",
    "$GL(\\infty )$ Toda hierarchy to the nonlinear Schr\\\"odinger (NLS) hierarchy.\n",
    "The invariance of the string equation under the NLS flows is worked out. Also\n",
    "the quantization of the integration constant $\\alpha$ reported by Hollowood et\n",
    "al. is explained by the analyticity of the continuum limit.\n",
    "\\\\\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "We will do the following steps:\n",
    "    1. extract all the authors as nodes, and the collaboration as edges with the weight of the number of collaborations.\n",
    "    2. extract the title as the name of the paper, the number of arxiv and attribute them to the nodes.\n",
    "    3. find communities in the graph.\n",
    "    5. use citation data to find the most important communities.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "example of assets/Cit-HepTh.txt:\n",
    "# Directed graph (each unordered pair of nodes is saved once): assets/Cit-HepTh.txt \n",
    "# Paper citation network of Arxiv High Energy Physics Theory category\n",
    "# Nodes: 27770 Edges: 352807\n",
    "# FromNodeId\tToNodeId\n",
    "0001001\t9304045\n",
    "0001001\t9308122\n",
    "0001001\t9309097\n",
    "0001001\t9311042\n",
    "0001001\t9401139\n",
    "\n",
    "for each paper, we will add a new attribute of list that shows all the papers that this paper cite, with its arxiv number.\n",
    "We will add it iff both papers of a citation are in the paper. And save it to arxiv_papers.json.\n",
    "\n",
    "example of temp/papers_standardized.json\n",
    "\n",
    "  {\n",
    "    \"paper_id\": \"hep-th/9211063\",\n",
    "    \"from\": \"Malcolm Perry <M.J.Perry@damtp.cambridge.ac.uk>\",\n",
    "    \"submitted\": \"Sat, 14 Nov 92 17:58:35 GMT (27kb)\",\n",
    "    \"title\": \"Topological Conformal Gravity in Four Dimensions\",\n",
    "    \"authors\": [\n",
    "      \"Malcolm J. Perry\",\n",
    "      \"Edward Teo\"\n",
    "    ],\n",
    "    \"comments\": \"35 pages, harvmac, DAMTP R92/42\",\n",
    "    \"report_no\": null,\n",
    "    \"journal_ref\": \"Nucl.Phys. B401 (1993) 206-238\",\n",
    "    \"subject_class\": null,\n",
    "    \"proxy\": null,\n",
    "    \"abstract\": \"In this paper, we present a new formulation of topological conformal gravity in four dimensions. Such a theory was first considered by Witten as a possible gravitational counterpart of topological Yang-Mills theory, but several problems left it incomplete. The key in our approach is to realise a theory which describes deformations of conformally self-dual gravitational instantons. We first identify the appropriate elliptic complex which does precisely this. By applying the Atiyah-Singer index theorem, we calculate the number of independent deformations of a given gravitational instanton which preserve its self-duality. We then quantise topological conformal gravity by BRST gauge-fixing, and discover how the quantum theory is naturally described by the above complex. Indeed, it is a process which closely parallels that of the Yang-Mills theory, and we show how the partition function generates an uncanny gravitational analogue of the first Donaldson invariant.\",\n",
    "    \"year\": 1992\n",
    "  },\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#load data from temp/papers_standardized.json\n",
    "with open(\"temp/papers_standardized.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers = {paper[\"paper_id\"]: paper for paper in json.load(f)}\n",
    "\n",
    "\n",
    "# Load the citation data\n",
    "citations = {}\n",
    "with open(\"assets/Cit-HepTh.txt\", \"r\") as f:\n",
    "    # Skip the lines with comments\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line.startswith(\"#\"):\n",
    "            break\n",
    "    for line in f:\n",
    "        source, target = map(int, line.strip().split())\n",
    "        source = str(source)\n",
    "        target = str(target)\n",
    "        if source in papers and target in papers:\n",
    "            if source not in citations:\n",
    "                citations[source] = []\n",
    "            citations[source].append(target)\n",
    "\n",
    "# Add the citation of the papers and the paper cited by the papers\n",
    "for paper_id, data in papers.items():\n",
    "    if paper_id in citations:\n",
    "        data[\"citations\"] = citations[paper_id]\n",
    "    else:\n",
    "        data[\"citations\"] = []\n",
    "\n",
    "\n",
    "# Save the updated data\n",
    "with open(\"temp/arxiv_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 8187\n",
      "Number of edges: 19205\n"
     ]
    }
   ],
   "source": [
    "# create a graph with authors as nodes and collaborations as edges\n",
    "import networkx as nx\n",
    "Ghep = nx.Graph()\n",
    "for paper in papers.values():\n",
    "    for author in paper[\"authors\"]:\n",
    "        if author not in Ghep:\n",
    "            Ghep.add_node(author, papers=[])\n",
    "            # Add the paper with its arxiv numbres to the author's list \n",
    "        Ghep.nodes[author][\"papers\"].append(paper[\"title\"])\n",
    "\n",
    "    for author1 in paper[\"authors\"]:\n",
    "        for author2 in paper[\"authors\"]:\n",
    "            if author1 != author2:\n",
    "                if not Ghep.has_edge(author1, author2):\n",
    "                    Ghep.add_edge(author1, author2, weight=0)\n",
    "                Ghep[author1][author2][\"weight\"] += 1\n",
    "\n",
    "print(f\"Number of nodes: {Ghep.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {Ghep.number_of_edges()}\")\n",
    "\n",
    "#print all the authors with the number of collaborations in temp/authors.csv in alphabetical order\n",
    "with open(\"temp/authors_list.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Author,Number of collaborations\\n\")\n",
    "    for author in sorted(Ghep.nodes):\n",
    "        f.write(f\"{author},{Ghep.degree(author)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542\n",
      "1161\n",
      "1994\n"
     ]
    }
   ],
   "source": [
    "# find communities in the graph\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "\n",
    "# Louvain community detection\n",
    "lc_Ghep = louvain_communities(Ghep,resolution=40.0, seed=123)\n",
    "\n",
    "#print the community number\n",
    "print(len(lc_Ghep))\n",
    "# Clique percolation method\n",
    "from networkx.algorithms.community import k_clique_communities\n",
    "cp_Ghep= k_clique_communities(Ghep,3)\n",
    "#print the community number\n",
    "print(len(list(cp_Ghep)))\n",
    "\n",
    "\n",
    "\n",
    "# label propagation algorithm\n",
    "from networkx.algorithms.community.label_propagation import label_propagation_communities\n",
    "lp_Ghep = list(label_propagation_communities(Ghep))\n",
    "#print the community number\n",
    "print(len(lp_Ghep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important communities:\n",
      "Community 1: 23 authors, 3146.0 citations\n",
      "  Shimon Yankielowicz\n",
      "  A. Loewy\n",
      "  Michael E. Peskin\n",
      "  Ori J. Ganor\n",
      "  Adi Armoni\n",
      "  Yoav Lavi\n",
      "  Ehud Schreiber\n",
      "  Y. Kinar\n",
      "  N. Sochen J. Sonnenschein\n",
      "  Vadim S. Kaplunovsky\n",
      "  Shlomo S. Razamat\n",
      "  Morten Krogh\n",
      "  Yitzhak Frishman\n",
      "  Ofer Aharony\n",
      "  Eugene A. Mirabelli\n",
      "  Y. Artstein\n",
      "  Mordechai Spiegelglas\n",
      "  S. Yankielowizc\n",
      "  Aaron Bergman\n",
      "  Joanna L. Karczmarek\n",
      "  Andreas Brandhuber\n",
      "  C. Sonnenschein\n",
      "  Nissan Itzhaki\n",
      "Community 2: 14 authors, 2179.0 citations\n",
      "  Mirjam Cvetic\n",
      "  Harald H. Soleng\n",
      "  R. L. Davis\n",
      "  Paul Langacker\n",
      "  Lisa Everett\n",
      "  Mirjam Cvetiv C\n",
      "  Kwanleung Chan\n",
      "  Donam Youm\n",
      "  Gerald B. Cleaver\n",
      "  Mirjam Cvetivc\n",
      "  Philip J. Rosenthal\n",
      "  David C. Lewellen\n",
      "  Stephen Griffies\n",
      "  Jose R. Espinosa\n",
      "Community 3: 15 authors, 2129.0 citations\n",
      "  Curtis G. Callan\n",
      "  Arkadas Ozakin\n",
      "  Michael Krasnitz\n",
      "  Vyacheslav S. Rychkov\n",
      "  Christof Schmidhuber\n",
      "  Christopher P. Herzog\n",
      "  Krev Simir Demeterfi\n",
      "  Ali Yegulalp\n",
      "  Peter Ouyang\n",
      "  G.V. Bhanot\n",
      "  Igor R. Klebanov\n",
      "  Steven S. Gubser\n",
      "  Akikazu Hashimoto\n",
      "  A. M. Polyakov\n",
      "  Shivaji L. Sondhi\n",
      "Community 4: 11 authors, 1927.0 citations\n",
      "  Iouri Chepelev\n",
      "  Hongya Liu\n",
      "  Guowen Peng\n",
      "  Arkady A. Tseytlin\n",
      "  Jeremy Michelson\n",
      "  Jorge G. Russo\n",
      "  R.R. Metsaev\n",
      "  Angelos Fotopoulos\n",
      "  Daniele Amati\n",
      "  Junseong Heo\n",
      "  Lawrence M. Krauss\n",
      "Community 5: 16 authors, 1895.0 citations\n",
      "  Tamas Hauer\n",
      "  Amer Iqbal\n",
      "  K. Ranganathan\n",
      "  Leonardo Rastelli\n",
      "  Alexander Belopolsky\n",
      "  Wangchang Su\n",
      "  R. Saroja\n",
      "  O. Bertolami\n",
      "  Oliver Dewolfe\n",
      "  Sabbir Rahman\n",
      "  Jaydeep Majumder\n",
      "  Hidenori Sonoda\n",
      "  M. C. Bento\n",
      "  Anjan Ananda Sen\n",
      "  Davide Gaiotto\n",
      "  Barton Zwiebach\n",
      "Community 6: 13 authors, 1856.0 citations\n",
      "  A. Resturccia\n",
      "  Riccardo Dauria\n",
      "  Laura Andrianopoli\n",
      "  S. Ferrara Amd M. A. Lledo\n",
      "  A.C. Cadavid\n",
      "  Silvia Vaula\n",
      "  M. Villasante\n",
      "  T. Magri\n",
      "  V.S.V. Varadarajan\n",
      "  T. Regge\n",
      "  Floriana Gargiulo\n",
      "  Anna Ceresole\n",
      "  Sergio Ferrara\n",
      "Community 7: 20 authors, 1617.0 citations\n",
      "  Erick A. Roura\n",
      "  Bugra Borasoy\n",
      "  Hsienchung Kao\n",
      "  Tzedan Chung\n",
      "  Georgios Metikas\n",
      "  Seoktae Koh\n",
      "  Kyoungtae Kimm\n",
      "  Jin Hur\n",
      "  Gungwon Kang\n",
      "  Pablo J. Marrero\n",
      "  Yuval Neeman\n",
      "  Piljin Yi\n",
      "  W.F. Chen. H.C. Lee\n",
      "  Nathan Salwen\n",
      "  W. S. Lyi\n",
      "  Yoji Michishita\n",
      "  Minyoung Choi\n",
      "  Paul F. Mende\n",
      "  Yun Soo Myung\n",
      "  Branko Urosevic\n",
      "Community 8: 17 authors, 1487.0 citations\n",
      "  J.R. Anglin\n",
      "  Hoseong La\n",
      "  David C. Page\n",
      "  Frederic Leblond\n",
      "  Vipul Periwal\n",
      "  Kenneth J. Lovis\n",
      "  J.D. Cohn\n",
      "  Ramzi R. Khuri\n",
      "  J. C. Breckenridge\n",
      "  Clifford V. Johnson\n",
      "  Adel M. Awad\n",
      "  Luc Marleau\n",
      "  David J. Winters\n",
      "  O Yvind Tafjord\n",
      "  G. Michaud\n",
      "  Laur Jarv\n",
      "  Robert C. Myers\n",
      "Community 9: 16 authors, 1456.0 citations\n",
      "  Seiji Terashima\n",
      "  Kazuhiro Sakai\n",
      "  Yasuhiko Yamada\n",
      "  Katsushi Ito\n",
      "  Tohru Eguchi\n",
      "  Takeo Araki\n",
      "  Ianwoo Kim\n",
      "  Byungkoo Lee\n",
      "  Kenji Mohri\n",
      "  Koichi Yoshioka\n",
      "  Jiro Hashiba\n",
      "  Hiroaki Kanno\n",
      "  Huanxiong Yang\n",
      "  Kyungseok Cha\n",
      "  Yoko Onjo\n",
      "  Toshiya Kawai\n",
      "Community 10: 12 authors, 1408.0 citations\n",
      "  Augusto Sagnotti\n",
      "  Gianfranco Pradisi\n",
      "  Jihad Mourad\n",
      "  Stefano Kovacs\n",
      "  Massimo Bianchi\n",
      "  Carlo Angelantonj\n",
      "  Fabio Riccioni\n",
      "  Giancarlo Rossi\n",
      "  Yassen S. Stanev\n",
      "  Emilian Dudas\n",
      "  C. Timirgaziu\n",
      "  Giuseppe Dappollonio\n"
     ]
    }
   ],
   "source": [
    "#calculate the net citations numbers between communities directly from the temp/arxiv_papers.json\n",
    "\n",
    "\"\"\"\n",
    "First few lines of the temp/arxiv_papers.json:\n",
    "{\n",
    "    \"9203077\": {\n",
    "        \"title\": \"Finite W-algebras\",\n",
    "        \"authors\": [\n",
    "            \"T.Tjin\"\n",
    "        ],\n",
    "        \"citations\": 13,\n",
    "        \"cited_by\": []\n",
    "    },\n",
    "    \"9203063\": {\n",
    "        \"title\": \"The Spectrum of Sl(2, R)/U(1) Black Hole Conformal Field Theory\",\n",
    "        \"authors\": [\n",
    "            \"Dileep P. Jatkar\"\n",
    "        ],\n",
    "        \"citations\": 0,\n",
    "        \"cited_by\": []\n",
    "    },\n",
    "    \"9212146\": {\n",
    "\"\"\"\n",
    "communities = list(lc_Ghep)  # Use the Louvain communities\n",
    "# Load the papers data\n",
    "with open(\"temp/arxiv_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    papers = json.load(f)\n",
    "\n",
    "# Create a dictionary of authors to communities\n",
    "author_community = {}\n",
    "for i, community in enumerate(communities):\n",
    "    for author in community:\n",
    "        author_community[author] = i\n",
    "\n",
    "# Calculate the net citations between communities\n",
    "net_citations = np.zeros((len(communities), len(communities)))\n",
    "for paper in papers.values():\n",
    "    if \"citations\" not in paper:\n",
    "        continue\n",
    "    # Ensure the source author exists in the author_community dictionary\n",
    "    if paper[\"authors\"]:\n",
    "        source_community = author_community.get(paper[\"authors\"][0], -1)\n",
    "        if source_community != -1:\n",
    "            for target in paper[\"citations\"]:\n",
    "                # Ensure the target paper exists and has authors\n",
    "                if target in papers and papers[target][\"authors\"]:\n",
    "                    target_community = author_community.get(papers[target][\"authors\"][0], -1)\n",
    "                    if target_community != -1:\n",
    "                        net_citations[source_community, target_community] += 1\n",
    "\n",
    "\n",
    "# Find the most important communities by net citations/\n",
    "community_citations = net_citations.sum(axis=1)\n",
    "most_important_communities = np.argsort(community_citations)[::-1]  \n",
    "\n",
    "print(\"Most important communities:\")\n",
    "for i in range(10):\n",
    "    community = communities[most_important_communities[i]]\n",
    "    print(f\"Community {i + 1}: {len(community)} authors, {community_citations[most_important_communities[i]]} citations\")\n",
    "    for author in community:\n",
    "        print(f\"  {author}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1542\n",
      "Number of edges: 13053\n"
     ]
    }
   ],
   "source": [
    "#create a graph of communities as summation of the information of the authors named after the most important author in the community.\n",
    "# we will create a graph of communities as summation of the information of the authors named after the most important author in the community. \n",
    "# The number of citations as the weight of the edges.\n",
    "G_communities = nx.Graph()\n",
    "for i, community in enumerate(communities):\n",
    "    most_important_author = max(community, key=lambda x: len(papers[x][\"papers\"]) if x in papers else 0)\n",
    "    G_communities.add_node(i, name=most_important_author, size=len(community))\n",
    "    #add the number of members in the community as the size of the node\n",
    "    #add the authors as attributes to the node\n",
    "    for author in community:\n",
    "        if author in papers:\n",
    "            #add the papers of the author to the node\n",
    "            G_communities.nodes[i][author] = papers[author][\"papers\"]\n",
    "            #add the authors of the author to the node\n",
    "            G_communities.nodes[i][\"authors\"] = papers[author][\"authors\"]\n",
    "\n",
    "    #add the total citations in the community\n",
    "    G_communities.nodes[i][\"total_citations\"] = community_citations[i]\n",
    "\n",
    "# Create the edges between communities based on the net citations\n",
    "for i in range(len(communities)):\n",
    "    for j in range(i + 1, len(communities)):\n",
    "        # Add the number of citations as the weight of the edge with weight of the number of citations\n",
    "        if net_citations[i][j] > 0:\n",
    "            G_communities.add_edge(i, j, weight=net_citations[i][j])\n",
    "\n",
    "print(f\"Number of nodes: {G_communities.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G_communities.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cff353013e4db3954284075694c399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sigma(nx.Graph with 1,542 nodes and 13,053 edges)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the graph of G_communities with ipysigma\n",
    "\n",
    "# Assign colors to each communities based on the numbers of members of communities from red to blue\n",
    "\n",
    "for node in G_communities.nodes:\n",
    "    r = max(0, min(255, 255 - 20 * len(communities[node])))\n",
    "    g = max(0, min(255, 20 * len(communities[node])))\n",
    "    G_communities.nodes[node][\"colors\"] = f\"rgb({r}, O,{g})\"\n",
    "\n",
    "# assgin the color of the edges based on the citations of the community\n",
    "for i, j in G_communities.edges:\n",
    "    G_communities.edges[i, j][\"color\"] = f\"rgb({255 - 20 * net_citations[i, j]}, {20 * net_citations[i, j]}, 0)\"\n",
    "    \n",
    "# Assign the size of the nodes based on citations\n",
    "for node in G_communities.nodes:\n",
    "    G_communities.nodes[node][\"size\"] = G_communities.nodes[node][\"total_citations\"] / 100\n",
    "\n",
    "# Visualize with ipysigma\n",
    "sigma = Sigma(\n",
    "    G_communities,\n",
    "    node_color=\"colors\",\n",
    "    edge_color=\"color\",\n",
    "    node_label=\"name\",\n",
    "    node_size=\"size\",\n",
    "    label_font=\"cursive\",\n",
    "    default_edge_type=\"curve\"\n",
    ")\n",
    "\n",
    "sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
