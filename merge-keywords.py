import json
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from sklearn.decomposition import PCA
from collections import defaultdict
import numpy as np
import hdbscan
import gc


# ======== åŠ è½½æ•°æ® ==========
with open("keywords_extracted.json", "r") as f:
    data = json.load(f)

# ======== æå–æ‰€æœ‰å…³é”®è¯çŸ­è¯­ ==========
all_keywords = set()
for paper in data:
    all_keywords.update(paper["keywords"])
all_keywords = sorted(all_keywords)



# ======== ç¼–ç å…³é”®è¯çŸ­è¯­ ==========
model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = model.encode(all_keywords, show_progress_bar=True)



# ======== é‡Šæ”¾æ¨¡å‹å‡å°‘å†…å­˜ ==========
del model
gc.collect()

# ======== é™ç»´å¤„ç† ==========

pca = PCA(n_components=50)
reduced_embeddings = pca.fit_transform(embeddings.astype(np.float32))



# ======== èšç±»åˆå¹¶ç›¸ä¼¼å…³é”®è¯ ==========

clusterer = hdbscan.HDBSCAN(min_cluster_size=3)
labels = clusterer.fit_predict(reduced_embeddings)



# ======== æ„å»ºå…³é”®è¯åˆå¹¶æ˜ å°„ ==========
clusters = defaultdict(list)
for kw, label in zip(all_keywords, labels):
    if label == -1:
        clusters[kw].append(kw)  # ç‹¬ç«‹å…³é”®è¯è‡ªå·±å½’ç±»
    else:
        clusters[label].append(kw)

merge_dict = {}
for group in clusters.values():
    sorted_group = sorted(group)
    rep = min(sorted_group, key=len)
    for var in sorted_group:
        merge_dict[var] = rep

# ======== æ›¿æ¢æ¯ç¯‡æ–‡ç« ä¸­çš„å…³é”®è¯ ==========
result = []
for paper in tqdm(data, desc="ğŸ§¹ æ›¿æ¢åˆå¹¶å…³é”®è¯"):
    new_keywords = [merge_dict.get(kw, kw) for kw in paper["keywords"]]
    deduped = sorted(set(new_keywords))
    result.append({
        "paper_id": paper["paper_id"],
        "title": paper["title"],
        "keywords": deduped
    })

# ======== ä¿å­˜æ–‡ä»¶ ==========
output_path = "./keywords_merged.json"
with open(output_path, "w") as f:
    json.dump(result, f, indent=2)



# ======== åå‘æ˜ å°„ï¼šä»£è¡¨è¯ â åŒä¹‰è¯åˆ—è¡¨ ==========
from collections import defaultdict

reverse_merge_dict = defaultdict(list)
for variant, rep in merge_dict.items():
    reverse_merge_dict[rep].append(variant)

# æŒ‰ä»£è¡¨è¯æ’åºï¼Œç»„å†…æ’åº
cluster_dict = {
    rep: sorted(variants)
    for rep, variants in sorted(reverse_merge_dict.items())
    if len(variants) > 1  # åªæ˜¾ç¤ºå‘ç”Ÿäº†åˆå¹¶çš„
}

# ä¿å­˜ä¸º JSON æ–‡ä»¶
with open("keyword_clusters.json", "w") as f:
    json.dump(cluster_dict, f, indent=4, ensure_ascii=False)


